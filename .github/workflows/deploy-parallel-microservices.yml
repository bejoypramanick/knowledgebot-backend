name: Build and Deploy All Micro-Services

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      force_rebuild_all:
        description: 'Force rebuild all services (ignore change detection)'
        required: false
        default: 'false'
        type: boolean

env:
  AWS_REGION: ap-south-1
  ECR_REGISTRY: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.ap-south-1.amazonaws.com
  ECR_REPOSITORY_PREFIX: knowledgebot

jobs:
  # Build all layers in parallel first
  build-layers:
    runs-on: ubuntu-latest
    environment: chatbot
    strategy:
      matrix:
        include:
          # Base Layers (all independent now)
          - name: base-layer
            dockerfile: layers/Dockerfile.base-layer
            size: "~50MB"
          - name: core-layer
            dockerfile: layers/Dockerfile.core-layer
            size: "~80MB"
          - name: database-layer
            dockerfile: layers/Dockerfile.database-layer
            size: "~150MB"
          - name: ml-layer
            dockerfile: layers/Dockerfile.ml-layer
            size: "~400MB"
          
          # Granular OCR Layers
          - name: pdf-processor-layer
            dockerfile: layers/Dockerfile.pdf-processor-layer
            size: "~200MB"
          - name: easyocr-layer
            dockerfile: layers/Dockerfile.easyocr-layer
            size: "~300MB"
          - name: table-detector-layer
            dockerfile: layers/Dockerfile.table-detector-layer
            size: "~400MB"
          - name: docling-core-layer
            dockerfile: layers/Dockerfile.docling-core-layer
            size: "~500MB"
          - name: docling-ocr-layer
            dockerfile: layers/Dockerfile.docling-ocr-layer
            size: "~800MB"
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Ensure ECR Repository Exists
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
      run: |
        echo "🔍 Ensuring ECR repository exists for layer: ${{ matrix.name }}"
        
        # Check if repository exists, create if it doesn't
        if ! aws ecr describe-repositories --repository-names $ECR_REPOSITORY_PREFIX-${{ matrix.name }} --region $AWS_REGION >/dev/null 2>&1; then
          echo "📦 Creating ECR repository: $ECR_REPOSITORY_PREFIX-${{ matrix.name }}"
          aws ecr create-repository \
            --repository-name $ECR_REPOSITORY_PREFIX-${{ matrix.name }} \
            --region $AWS_REGION \
            --image-scanning-configuration scanOnPush=true
        else
          echo "✅ ECR repository already exists: $ECR_REPOSITORY_PREFIX-${{ matrix.name }}"
        fi

    - name: Build Layer ${{ matrix.name }}
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        echo "🏗️ Building layer: ${{ matrix.name }} (${{ matrix.size }})"
        
        # Build layer directly
        docker build -f ${{ matrix.dockerfile }} -t $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:$IMAGE_TAG .
        
        # Tag as latest
        docker tag $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:latest
        
        # Push both tags
        docker push $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:$IMAGE_TAG
        docker push $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:latest
        
        echo "✅ Built and pushed layer: ${{ matrix.name }}"

    - name: Output build details
      run: |
        echo "📦 Layer: $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:$IMAGE_TAG"
        echo "📏 Size: ${{ matrix.size }}"

  # Build all services in parallel after layers are ready
  build-services:
    needs: build-layers
    runs-on: ubuntu-latest
    environment: chatbot
    strategy:
      max-parallel: 2
      matrix:
        include:
          # Core Micro-Services
          - name: presigned-url
            dockerfile: Dockerfile.presigned-url-layered
            base_layer: base-layer
            size: "~55MB"
            memory: 256
            timeout: 30
          - name: s3-reader
            dockerfile: Dockerfile.s3-reader-layered
            base_layer: core-layer
            size: "~85MB"
            memory: 256
            timeout: 30
          - name: pinecone-search
            dockerfile: Dockerfile.pinecone-search-layered
            base_layer: database-layer
            size: "~155MB"
            memory: 512
            timeout: 60
          - name: pinecone-upsert
            dockerfile: Dockerfile.pinecone-upsert-layered
            base_layer: database-layer
            size: "~155MB"
            memory: 512
            timeout: 60
          - name: neo4j-search
            dockerfile: Dockerfile.neo4j-search-layered
            base_layer: database-layer
            size: "~155MB"
            memory: 512
            timeout: 60
          - name: neo4j-write
            dockerfile: Dockerfile.neo4j-write-layered
            base_layer: database-layer
            size: "~155MB"
            memory: 512
            timeout: 60
          - name: dynamodb-crud
            dockerfile: Dockerfile.dynamodb-crud-layered
            base_layer: core-layer
            size: "~85MB"
            memory: 256
            timeout: 30
          - name: text-chunker
            dockerfile: Dockerfile.text-chunker-layered
            base_layer: base-layer
            size: "~55MB"
            memory: 256
            timeout: 30
          - name: embedding-generator
            dockerfile: Dockerfile.embedding-generator-layered
            base_layer: ml-layer
            size: "~405MB"
            memory: 1024
            timeout: 120
          - name: rag-search
            dockerfile: Dockerfile.rag-search-layered
            base_layer: ml-layer
            size: "~405MB"
            memory: 1024
            timeout: 180
          - name: chat-generator
            dockerfile: Dockerfile.chat-generator-layered
            base_layer: ml-layer
            size: "~405MB"
            memory: 1024
            timeout: 300
          
          # Granular OCR Micro-Services
          - name: pdf-processor
            dockerfile: Dockerfile.pdf-processor-layered
            base_layer: pdf-processor-layer
            size: "~255MB"
            memory: 1024
            timeout: 120
          - name: easyocr
            dockerfile: Dockerfile.easyocr-layered
            base_layer: easyocr-layer
            size: "~355MB"
            memory: 1024
            timeout: 180
          - name: table-detector
            dockerfile: Dockerfile.table-detector-layered
            base_layer: table-detector-layer
            size: "~455MB"
            memory: 1024
            timeout: 240
          - name: docling-core
            dockerfile: Dockerfile.docling-core-layered
            base_layer: docling-core-layer
            size: "~555MB"
            memory: 1024
            timeout: 300
          - name: docling-ocr
            dockerfile: Dockerfile.docling-ocr-layered
            base_layer: docling-ocr-layer
            size: "~855MB"
            memory: 1024
            timeout: 300
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Ensure ECR Repository Exists
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
      run: |
        echo "🔍 Ensuring ECR repository exists for service: ${{ matrix.name }}"
        
        # Check if repository exists, create if it doesn't
        if ! aws ecr describe-repositories --repository-names $ECR_REPOSITORY_PREFIX-${{ matrix.name }} --region $AWS_REGION >/dev/null 2>&1; then
          echo "📦 Creating ECR repository: $ECR_REPOSITORY_PREFIX-${{ matrix.name }}"
          aws ecr create-repository \
            --repository-name $ECR_REPOSITORY_PREFIX-${{ matrix.name }} \
            --region $AWS_REGION \
            --image-scanning-configuration scanOnPush=true
        else
          echo "✅ ECR repository already exists: $ECR_REPOSITORY_PREFIX-${{ matrix.name }}"
        fi
        
        # For services with base layers, ensure base layer repository exists
        if [ "${{ matrix.base_layer }}" != "none" ] && [ -n "${{ matrix.base_layer }}" ]; then
          echo "🔍 Ensuring base layer ECR repository exists: ${{ matrix.base_layer }}"
          if ! aws ecr describe-repositories --repository-names $ECR_REPOSITORY_PREFIX-${{ matrix.base_layer }} --region $AWS_REGION >/dev/null 2>&1; then
            echo "📦 Creating base layer ECR repository: $ECR_REPOSITORY_PREFIX-${{ matrix.base_layer }}"
            aws ecr create-repository \
              --repository-name $ECR_REPOSITORY_PREFIX-${{ matrix.base_layer }} \
              --region $AWS_REGION \
              --image-scanning-configuration scanOnPush=true
          else
            echo "✅ Base layer ECR repository already exists: $ECR_REPOSITORY_PREFIX-${{ matrix.base_layer }}"
          fi
        fi

    - name: Build Service ${{ matrix.name }}
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        echo "🏗️ Building service: ${{ matrix.name }} (${{ matrix.size }})"
        
        if [ "${{ matrix.base_layer }}" != "none" ] && [ -n "${{ matrix.base_layer }}" ]; then
          echo "📦 Using base layer: ${{ matrix.base_layer }}"
          
          # Import the base layer from ECR with retry mechanism
          max_retries=5
          retry_count=0
          
          while [ $retry_count -lt $max_retries ]; do
            echo "🔄 Attempting to pull base layer (attempt $((retry_count + 1))/$max_retries)..."
            
            if docker pull $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.base_layer }}:latest; then
              echo "✅ Successfully pulled base layer"
              break
            else
              retry_count=$((retry_count + 1))
              if [ $retry_count -lt $max_retries ]; then
                echo "⏳ Waiting 30 seconds before retry..."
                sleep 30
              else
                echo "❌ Failed to pull base layer after $max_retries attempts"
                exit 1
              fi
            fi
          done
          
          # Tag it locally for the build
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.base_layer }}:latest knowledgebot-${{ matrix.base_layer }}:latest
          
          # Build the service using the imported layer
          docker build -f ${{ matrix.dockerfile }} -t $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:$IMAGE_TAG .
        else
          echo "📦 Building standalone service (no base layer)"
          # Build service directly without base layer
          docker build -f ${{ matrix.dockerfile }} -t $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:$IMAGE_TAG .
        fi
        
        # Tag as latest
        docker tag $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:latest
        
        # Push both tags
        docker push $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:$IMAGE_TAG
        docker push $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:latest
        
        echo "✅ Built and pushed service: ${{ matrix.name }}"

    - name: Deploy Service ${{ matrix.name }}
      if: github.ref == 'refs/heads/main'
      env:
        IMAGE_URI: ${{ env.ECR_REGISTRY }}/${{ env.ECR_REPOSITORY_PREFIX }}-${{ matrix.name }}:${{ github.sha }}
      run: |
        echo "🚀 Deploying ${{ matrix.name }} microservice"
        
        # Check if function exists
        if aws lambda get-function --function-name knowledgebot-${{ matrix.name }} >/dev/null 2>&1; then
          echo "🔄 Updating existing microservice: knowledgebot-${{ matrix.name }}"
          
          # Update function code with retry logic
          echo "🔄 Updating function code..."
          for attempt in 1 2 3 4 5; do
            echo "Attempt $attempt of 5"
            if aws lambda update-function-code \
              --function-name knowledgebot-${{ matrix.name }} \
              --image-uri $IMAGE_URI \
              --region $AWS_REGION; then
              echo "✅ Function code updated successfully"
              break
            fi
            
            if [ $attempt -lt 5 ]; then
              wait_time=$((attempt * 30))
              echo "⏳ Waiting $wait_time seconds before retry..."
              sleep $wait_time
            else
              echo "❌ Failed to update function code after 5 attempts"
              exit 1
            fi
          done
          
          # Set environment variables based on service type
          case "${{ matrix.name }}" in
            "presigned-url")
              ENV_VARS=""
              ;;
            "pinecone-search"|"pinecone-upsert")
              ENV_VARS="PINECONE_API_KEY=${{ secrets.PINECONE_API_KEY }},PINECONE_INDEX_NAME=${{ secrets.PINECONE_INDEX_NAME }},PINECONE_HOST=${{ secrets.PINECONE_HOST }},PINECONE_DIMENSIONS=${{ secrets.PINECONE_DIMENSIONS }},PINECONE_ENVIRONMENT=${{ secrets.PINECONE_ENVIRONMENT }},PINECONE_METRIC=${{ secrets.PINECONE_METRIC }}"
              ;;
            "neo4j-search"|"neo4j-write")
              ENV_VARS="NEO4J_URI=${{ secrets.NEO4J_URI }},NEO4J_USER=${{ secrets.NEO4J_USER }},NEO4J_PASSWORD=${{ secrets.NEO4J_PASSWORD }}"
              ;;
            "embedding-generator")
              ENV_VARS="OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}"
              ;;
            "rag-search")
              ENV_VARS=""
              ;;
            "chat-generator")
              ENV_VARS="OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}"
              ;;
            *)
              ENV_VARS=""
              ;;
          esac
          
          # Update function configuration with retry logic
          echo "🔄 Updating function configuration..."
          for attempt in 1 2 3 4 5; do
            echo "Attempt $attempt of 5"
            if [ -n "$ENV_VARS" ]; then
              if aws lambda update-function-configuration \
                --function-name knowledgebot-${{ matrix.name }} \
                --memory-size ${{ matrix.memory }} \
                --timeout ${{ matrix.timeout }} \
                --environment Variables="{$ENV_VARS}" \
                --region $AWS_REGION; then
                echo "✅ Function configuration updated successfully"
                break
              fi
            else
              if aws lambda update-function-configuration \
                --function-name knowledgebot-${{ matrix.name }} \
                --memory-size ${{ matrix.memory }} \
                --timeout ${{ matrix.timeout }} \
                --region $AWS_REGION; then
                echo "✅ Function configuration updated successfully"
                break
              fi
            fi
            
            if [ $attempt -lt 5 ]; then
              wait_time=$((attempt * 30))
              echo "⏳ Waiting $wait_time seconds before retry..."
              sleep $wait_time
            else
              echo "❌ Failed to update function configuration after 5 attempts"
              exit 1
            fi
          done
        else
          echo "🆕 Creating new microservice: knowledgebot-${{ matrix.name }}"
          
          # Set environment variables based on service type
          case "${{ matrix.name }}" in
            "presigned-url")
              ENV_VARS=""
              ;;
            "pinecone-search"|"pinecone-upsert")
              ENV_VARS="PINECONE_API_KEY=${{ secrets.PINECONE_API_KEY }},PINECONE_INDEX_NAME=${{ secrets.PINECONE_INDEX_NAME }},PINECONE_HOST=${{ secrets.PINECONE_HOST }},PINECONE_DIMENSIONS=${{ secrets.PINECONE_DIMENSIONS }},PINECONE_ENVIRONMENT=${{ secrets.PINECONE_ENVIRONMENT }},PINECONE_METRIC=${{ secrets.PINECONE_METRIC }}"
              ;;
            "neo4j-search"|"neo4j-write")
              ENV_VARS="NEO4J_URI=${{ secrets.NEO4J_URI }},NEO4J_USER=${{ secrets.NEO4J_USER }},NEO4J_PASSWORD=${{ secrets.NEO4J_PASSWORD }}"
              ;;
            "embedding-generator")
              ENV_VARS="OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}"
              ;;
            "rag-search")
              ENV_VARS=""
              ;;
            "chat-generator")
              ENV_VARS="OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}"
              ;;
            *)
              ENV_VARS=""
              ;;
          esac
          
          # Create new function
          if [ -n "$ENV_VARS" ]; then
            aws lambda create-function \
              --function-name knowledgebot-${{ matrix.name }} \
              --package-type Image \
              --code ImageUri=$IMAGE_URI \
              --role arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/lambda-execution-role \
              --memory-size ${{ matrix.memory }} \
              --timeout ${{ matrix.timeout }} \
              --environment Variables="{$ENV_VARS}"
          else
            aws lambda create-function \
              --function-name knowledgebot-${{ matrix.name }} \
              --package-type Image \
              --code ImageUri=$IMAGE_URI \
              --role arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/lambda-execution-role \
              --memory-size ${{ matrix.memory }} \
              --timeout ${{ matrix.timeout }}
          fi
        fi
        
        echo "✅ Deployed knowledgebot-${{ matrix.name }} successfully"

    - name: Output build details
      run: |
        echo "📦 Service: $ECR_REGISTRY/$ECR_REPOSITORY_PREFIX-${{ matrix.name }}:$IMAGE_TAG"
        echo "📏 Size: ${{ matrix.size }}"
        echo "💾 Memory: ${{ matrix.memory }}MB"
        echo "⏱️ Timeout: ${{ matrix.timeout }}s"

  # Summary job
  deployment-summary:
    needs: [build-layers, build-services]
    runs-on: ubuntu-latest
    environment: chatbot
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Single Job Parallel Architecture Deployment Summary
      run: |
        echo "🎉 KnowledgeBot Single Job Parallel Micro-Services Deployment Complete!"
        echo ""
        echo "🏗️ Layers Built (9 layers):"
        echo "  • knowledgebot-base-layer (~50MB)"
        echo "  • knowledgebot-core-layer (~80MB)"
        echo "  • knowledgebot-database-layer (~150MB)"
        echo "  • knowledgebot-ml-layer (~400MB)"
        echo "  • knowledgebot-pdf-processor-layer (~200MB)"
        echo "  • knowledgebot-easyocr-layer (~300MB)"
        echo "  • knowledgebot-table-detector-layer (~400MB)"
        echo "  • knowledgebot-docling-core-layer (~500MB)"
        echo "  • knowledgebot-docling-full-layer (~1.2GB)"
        echo ""
        echo "📋 Micro-Services Deployed (16 services):"
        echo ""
        echo "🔧 Core Services:"
        echo "  • knowledgebot-presigned-url (256MB, 30s, ~55MB)"
        echo "  • knowledgebot-s3-reader (256MB, 30s, ~85MB)"
        echo "  • knowledgebot-pinecone-search (512MB, 60s, ~155MB)"
        echo "  • knowledgebot-pinecone-upsert (512MB, 60s, ~155MB)"
        echo "  • knowledgebot-neo4j-search (512MB, 60s, ~155MB)"
        echo "  • knowledgebot-neo4j-write (512MB, 60s, ~155MB)"
        echo "  • knowledgebot-dynamodb-crud (256MB, 30s, ~85MB)"
        echo "  • knowledgebot-text-chunker (256MB, 30s, ~55MB)"
        echo "  • knowledgebot-embedding-generator (1024MB, 120s, ~405MB)"
        echo "  • knowledgebot-rag-search (1024MB, 180s, ~405MB)"
        echo "  • knowledgebot-chat-generator (1024MB, 300s, ~405MB)"
        echo ""
        echo "📄 Granular OCR Services:"
        echo "  • knowledgebot-pdf-processor (1024MB, 120s, ~255MB)"
        echo "  • knowledgebot-easyocr (1024MB, 180s, ~355MB)"
        echo "  • knowledgebot-table-detector (1024MB, 240s, ~455MB)"
        echo "  • knowledgebot-docling-core (1024MB, 300s, ~555MB)"
        echo "  • knowledgebot-docling-full (2048MB, 900s, ~1.25GB)"
        echo ""
        echo "⚡ Single Job Parallel Processing Benefits:"
        echo "  • All 25 builds run simultaneously in one job"
        echo "  • No sequential dependencies between jobs"
        echo "  • Maximum GitHub Actions parallelism"
        echo "  • Fastest possible deployment"
        echo "  • Zero redundancy through ECR imports"
        echo "  • Build and deploy in same parallel child jobs"
        echo ""
        echo "📊 Total Architecture:"
        echo "  • Total Layers: 9 (~3.2GB)"
        echo "  • Total Services: 16 (~4.1GB)"
        echo "  • Total Storage: ~7.3GB"
        echo "  • Build Time: ~15 minutes (all parallel)"
        echo "  • Redundancy: 0% (shared layers)"
        echo ""
        echo "🔗 ECR Repositories:"
        echo "  • Registry: ${{ env.ECR_REGISTRY }}"
        echo "  • Prefix: ${{ env.ECR_REPOSITORY_PREFIX }}"
        echo "  • Total Images: 25 (9 layers + 16 services)"
