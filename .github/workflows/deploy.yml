name: Deploy KnowledgeBot Backend (Multi-Stage)

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch: # Allow manual trigger

env:
  AWS_REGION: ${{ secrets.AWS_REGION || 'ap-south-1' }}
  ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY || 'knowledgebot-backend' }}
  S3_BUCKET: ${{ secrets.S3_BUCKET || 'chatbot-storage-ap-south-1' }}
  DYNAMODB_TABLE: ${{ secrets.DYNAMODB_TABLE || 'chatbot-knowledge-base-metadata' }}
  KNOWLEDGE_BASE_TABLE: ${{ secrets.KNOWLEDGE_BASE_TABLE || 'chatbot-knowledge-base' }}
  CONVERSATIONS_TABLE: ${{ secrets.CONVERSATIONS_TABLE || 'chatbot-conversations' }}
  DOCUMENTS_BUCKET: ${{ secrets.DOCUMENTS_BUCKET || 'chatbot-documents-ap-south-1' }}
  EMBEDDINGS_BUCKET: ${{ secrets.EMBEDDINGS_BUCKET || 'chatbot-embeddings-ap-south-1' }}

jobs:
  # Job 1: Setup Infrastructure
  setup-infrastructure:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.ref == 'refs/heads/main'
    environment: chatbot
    
    permissions:
      id-token: write
      contents: read

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Create S3 bucket
      run: |
        echo "üì¶ Creating S3 bucket..."
        aws s3 mb s3://${{ env.S3_BUCKET }} --region ${{ env.AWS_REGION }} || echo "Bucket already exists"

    - name: Configure S3 CORS policy
      run: |
        echo "üîß Setting up S3 CORS policy..."
        aws s3api put-bucket-cors \
          --bucket ${{ env.S3_BUCKET }} \
          --cors-configuration '{
            "CORSRules": [
              {
                "AllowedOrigins": ["*"],
                "AllowedMethods": ["GET", "PUT", "POST", "DELETE", "HEAD"],
                "AllowedHeaders": ["*"],
                "MaxAgeSeconds": 3000
              }
            ]
          }' \
          --region ${{ env.AWS_REGION }}

    - name: Create DynamoDB tables
      run: |
        echo "üóÑÔ∏è Creating DynamoDB tables..."
        
        # Create knowledge base metadata table
        aws dynamodb create-table \
          --table-name ${{ env.DYNAMODB_TABLE }} \
          --attribute-definitions \
            AttributeName=document_id,AttributeType=S \
            AttributeName=created_at,AttributeType=S \
          --key-schema \
            AttributeName=document_id,KeyType=HASH \
          --global-secondary-indexes \
            IndexName=created_at-index,KeySchema=[{AttributeName=created_at,KeyType=HASH}],Projection={ProjectionType=ALL},ProvisionedThroughput={ReadCapacityUnits=5,WriteCapacityUnits=5} \
          --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
          --region ${{ env.AWS_REGION }} || echo "Table already exists"
        
        # Create knowledge base table
        aws dynamodb create-table \
          --table-name ${{ env.KNOWLEDGE_BASE_TABLE }} \
          --attribute-definitions \
            AttributeName=id,AttributeType=S \
          --key-schema \
            AttributeName=id,KeyType=HASH \
          --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
          --region ${{ env.AWS_REGION }} || echo "Table already exists"
        
        # Create conversations table
        aws dynamodb create-table \
          --table-name ${{ env.CONVERSATIONS_TABLE }} \
          --attribute-definitions \
            AttributeName=conversation_id,AttributeType=S \
            AttributeName=created_at,AttributeType=S \
          --key-schema \
            AttributeName=conversation_id,KeyType=HASH \
          --global-secondary-indexes \
            IndexName=created_at-index,KeySchema=[{AttributeName=created_at,KeyType=HASH}],Projection={ProjectionType=ALL},ProvisionedThroughput={ReadCapacityUnits=5,WriteCapacityUnits=5} \
          --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
          --region ${{ env.AWS_REGION }} || echo "Table already exists"

    - name: Create IAM role for Lambda
      run: |
        echo "üîê Creating IAM role for Lambda..."
        
        # Create trust policy
        cat > trust-policy.json << EOF
        {
          "Version": "2012-10-17",
          "Statement": [
            {
              "Effect": "Allow",
              "Principal": {
                "Service": "lambda.amazonaws.com"
              },
              "Action": "sts:AssumeRole"
            }
          ]
        }
        EOF
        
        # Create role
        aws iam create-role \
          --role-name chatbot-lambda-role \
          --assume-role-policy-document file://trust-policy.json \
          --region ${{ env.AWS_REGION }} || echo "Role already exists"
        
        # Attach basic execution policy
        aws iam attach-role-policy \
          --role-name chatbot-lambda-role \
          --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole \
          --region ${{ env.AWS_REGION }} || echo "Policy already attached"
        
        # Attach S3 policy
        aws iam attach-role-policy \
          --role-name chatbot-lambda-role \
          --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess \
          --region ${{ env.AWS_REGION }} || echo "Policy already attached"
        
        # Attach DynamoDB policy
        aws iam attach-role-policy \
          --role-name chatbot-lambda-role \
          --policy-arn arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess \
          --region ${{ env.AWS_REGION }} || echo "Policy already attached"

  # Job 2: Build Core Dependencies Image
  build-core-deps:
    runs-on: ubuntu-latest
    needs: setup-infrastructure
    if: always() && (needs.setup-infrastructure.result == 'success' || needs.setup-infrastructure.result == 'skipped')
    environment: chatbot
    
    permissions:
      id-token: write
      contents: read

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Create ECR repository if not exists
      run: |
        echo "üì¶ Ensuring ECR repository exists..."
        aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }}-core --region ${{ env.AWS_REGION }} || \
        aws ecr create-repository --repository-name ${{ env.ECR_REPOSITORY }}-core --region ${{ env.AWS_REGION }}

    - name: Build core dependencies image
      id: build-core
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        echo "üê≥ Building core dependencies image..."
        cat > Dockerfile.core << 'EOF'
        FROM public.ecr.aws/lambda/python:3.11
        
        # Install system dependencies
        RUN yum update -y && \
            yum install -y \
            gcc \
            gcc-c++ \
            make \
            cmake \
            git \
            wget \
            curl \
            unzip \
            libffi-devel \
            openssl-devel \
            libjpeg-devel \
            libpng-devel \
            libtiff-devel \
            freetype-devel \
            lcms2-devel \
            libwebp-devel \
            tcl-devel \
            tk-devel \
            libxml2-devel \
            libxslt-devel \
            zlib-devel \
            bzip2-devel \
            readline-devel \
            sqlite-devel \
            xz-devel \
            expat-devel \
            gdbm-devel \
            ncurses-devel \
            libuuid-devel \
            libffi-devel \
            python3-devel \
            && yum clean all
        
        # Create cache directories
        RUN mkdir -p /tmp/transformers_cache \
            /tmp/huggingface_cache \
            /tmp/huggingface_datasets_cache \
            /tmp/torch_cache \
            /tmp/sentence_transformers_cache
        
        # Install core Python dependencies with specific compatible versions
        RUN pip install --upgrade pip setuptools wheel && \
            pip install --no-cache-dir \
            openai==1.12.0 \
            agents==0.1.0 \
            boto3==1.34.0 \
            botocore==1.34.0 \
            pinecone-client==2.2.4 \
            neo4j==5.15.0 \
            sentence-transformers==2.2.2 \
            torch==2.1.0 \
            transformers==4.36.0 \
            numpy==1.24.3 \
            pandas==1.5.3 \
            pydantic==2.5.0 \
            typing-extensions==4.8.0 \
            python-dotenv==1.0.0 \
            requests==2.31.0 \
            httpx==0.25.0 \
            orjson==3.9.10 \
            structlog==23.2.0
        
        # Pre-download sentence transformer model
        RUN python -c "\
        import os; \
        os.environ['TRANSFORMERS_CACHE'] = '/tmp/transformers_cache'; \
        os.environ['HF_HOME'] = '/tmp/huggingface_cache'; \
        os.environ['HF_DATASETS_CACHE'] = '/tmp/huggingface_datasets_cache'; \
        os.environ['TORCH_HOME'] = '/tmp/torch_cache'; \
        os.environ['SENTENCE_TRANSFORMERS_HOME'] = '/tmp/sentence_transformers_cache'; \
        from sentence_transformers import SentenceTransformer; \
        model = SentenceTransformer('all-MiniLM-L6-v2'); \
        print('Sentence transformer model downloaded and cached'); \
        "
        EOF
        
        docker build -f Dockerfile.core -t $ECR_REGISTRY/${{ env.ECR_REPOSITORY }}-core:$IMAGE_TAG .
        docker push $ECR_REGISTRY/${{ env.ECR_REPOSITORY }}-core:$IMAGE_TAG
        echo "core-image=$ECR_REGISTRY/${{ env.ECR_REPOSITORY }}-core:$IMAGE_TAG" >> $GITHUB_OUTPUT

  # Job 3: Build Document Processing Image
  build-doc-processing:
    runs-on: ubuntu-latest
    needs: build-core-deps
    if: always() && (needs.build-core-deps.result == 'success' || needs.build-core-deps.result == 'skipped')
    environment: chatbot
    
    permissions:
      id-token: write
      contents: read

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Create ECR repository if not exists
      run: |
        echo "üì¶ Ensuring ECR repository exists..."
        aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }}-docs --region ${{ env.AWS_REGION }} || \
        aws ecr create-repository --repository-name ${{ env.ECR_REPOSITORY }}-docs --region ${{ env.AWS_REGION }}

    - name: Build document processing image
      id: build-docs
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        echo "üê≥ Building document processing image..."
        cat > Dockerfile.docs << 'EOF'
        FROM ${{ needs.build-core-deps.outputs.core-image }}
        
        # Install document processing dependencies
        RUN pip install --no-cache-dir \
            docling>=1.0.0 \
            PyPDF2>=3.0.0 \
            pdfplumber>=0.9.0 \
            python-docx>=0.8.11 \
            openpyxl>=3.1.0 \
            Pillow>=10.0.0 \
            opencv-python>=4.8.0 \
            python-magic>=0.4.27 \
            python-magic-bin>=0.4.14
        
        # Pre-download Docling models
        RUN python -c "\
        try: \
            from docling.document_converter import DocumentConverter; \
            from docling.datamodel.base_models import InputFormat; \
            from docling.datamodel.pipeline_options import PdfPipelineOptions; \
            converter = DocumentConverter(format_options={InputFormat.PDF: PdfPipelineOptions(do_ocr=True, do_table_structure=True, table_structure_options={'do_cell_matching': True})}); \
            print('Docling models downloaded and cached'); \
        except Exception as e: \
            print(f'Docling model download failed: {e}'); \
        "
        EOF
        
        docker build -f Dockerfile.docs -t $ECR_REGISTRY/${{ env.ECR_REPOSITORY }}-docs:$IMAGE_TAG .
        docker push $ECR_REGISTRY/${{ env.ECR_REPOSITORY }}-docs:$IMAGE_TAG
        echo "docs-image=$ECR_REGISTRY/${{ env.ECR_REPOSITORY }}-docs:$IMAGE_TAG" >> $GITHUB_OUTPUT

  # Job 4: Build NLP Processing Image
  build-nlp-processing:
    runs-on: ubuntu-latest
    needs: build-core-deps
    if: always() && (needs.build-core-deps.result == 'success' || needs.build-core-deps.result == 'skipped')
    environment: chatbot
    
    permissions:
      id-token: write
      contents: read

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Create ECR repository if not exists
      run: |
        echo "üì¶ Ensuring ECR repository exists..."
        aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }}-nlp --region ${{ env.AWS_REGION }} || \
        aws ecr create-repository --repository-name ${{ env.ECR_REPOSITORY }}-nlp --region ${{ env.AWS_REGION }}

    - name: Build NLP processing image
      id: build-nlp
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        echo "üê≥ Building NLP processing image..."
        cat > Dockerfile.nlp << 'EOF'
        FROM ${{ needs.build-core-deps.outputs.core-image }}
        
        # Install NLP processing dependencies
        RUN pip install --no-cache-dir \
            nltk>=3.8.0 \
            spacy>=3.6.0 \
            redis>=4.6.0 \
            python-decouple>=3.8
        
        # Download NLTK data
        RUN python -c "\
        import nltk; \
        nltk.download('punkt'); \
        nltk.download('stopwords'); \
        nltk.download('wordnet'); \
        print('NLTK data downloaded'); \
        "
        
        # Download spaCy model
        RUN python -c "\
        import spacy; \
        try: \
            spacy.cli.download('en_core_web_sm'); \
            print('spaCy model downloaded'); \
        except Exception as e: \
            print(f'spaCy model download failed: {e}'); \
        "
        EOF
        
        docker build -f Dockerfile.nlp -t $ECR_REGISTRY/${{ env.ECR_REPOSITORY }}-nlp:$IMAGE_TAG .
        docker push $ECR_REGISTRY/${{ env.ECR_REPOSITORY }}-nlp:$IMAGE_TAG
        echo "nlp-image=$ECR_REGISTRY/${{ env.ECR_REPOSITORY }}-nlp:$IMAGE_TAG" >> $GITHUB_OUTPUT

  # Job 5: Build Final Application Image
  build-final-app:
    runs-on: ubuntu-latest
    needs: [build-core-deps, build-doc-processing, build-nlp-processing]
    if: always() && (needs.build-core-deps.result == 'success' || needs.build-core-deps.result == 'skipped')
    environment: chatbot
    
    permissions:
      id-token: write
      contents: read

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Create ECR repository if not exists
      run: |
        echo "üì¶ Ensuring ECR repository exists..."
        aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }} || \
        aws ecr create-repository --repository-name ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }}

    - name: Build final application image
      id: build-final
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        echo "üê≥ Building final application image..."
        cat > Dockerfile.final << 'EOF'
        FROM ${{ needs.build-core-deps.outputs.core-image }}
        
        # Copy application code
        COPY agent-toolkit/crud_operations.py ${LAMBDA_TASK_ROOT}/
        COPY agent-toolkit/lambda_handlers.py ${LAMBDA_TASK_ROOT}/
        COPY agent-toolkit/rag_agent.py ${LAMBDA_TASK_ROOT}/
        COPY agent-toolkit/rag_operations.py ${LAMBDA_TASK_ROOT}/
        
        # Set environment variables
        ENV EMBEDDING_TYPE=local
        ENV EMBEDDING_MODEL=all-MiniLM-L6-v2
        
        # Set the CMD to your handler
        CMD ["lambda_handlers.lambda_handler"]
        EOF
        
        docker build -f Dockerfile.final -t $ECR_REGISTRY/${{ env.ECR_REPOSITORY }}:$IMAGE_TAG .
        docker push $ECR_REGISTRY/${{ env.ECR_REPOSITORY }}:$IMAGE_TAG
        echo "final-image=$ECR_REGISTRY/${{ env.ECR_REPOSITORY }}:$IMAGE_TAG" >> $GITHUB_OUTPUT

  # Job 6: Deploy Lambda Function
  deploy-lambda:
    runs-on: ubuntu-latest
    needs: [build-final-app, setup-infrastructure]
    if: always() && (needs.build-final-app.result == 'success' || needs.build-final-app.result == 'skipped')
    environment: chatbot
    
    permissions:
      id-token: write
      contents: read

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Deploy Lambda function
      run: |
        echo "üöÄ Deploying Lambda function..."
        
        # Create Lambda function
        aws lambda create-function \
          --function-name knowledgebot-backend \
          --package-type Image \
          --code ImageUri=${{ needs.build-final-app.outputs.final-image }} \
          --role arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):role/chatbot-lambda-role \
          --timeout 900 \
          --memory-size 3008 \
          --environment Variables='{
            "PINECONE_API_KEY":"${{ secrets.PINECONE_API_KEY }}",
            "PINECONE_ENVIRONMENT":"${{ secrets.PINECONE_ENVIRONMENT }}",
            "PINECONE_INDEX_NAME":"${{ secrets.PINECONE_INDEX_NAME }}",
            "PINECONE_HOST":"${{ secrets.PINECONE_HOST }}",
            "PINECONE_DIMENSIONS":"${{ secrets.PINECONE_DIMENSIONS }}",
            "PINECONE_METRIC":"${{ secrets.PINECONE_METRIC }}",
            "NEO4J_URI":"${{ secrets.NEO4J_URI }}",
            "NEO4J_USER":"${{ secrets.NEO4J_USER }}",
            "NEO4J_PASSWORD":"${{ secrets.NEO4J_PASSWORD }}",
            "AWS_REGION":"${{ env.AWS_REGION }}",
            "DYNAMODB_TABLE":"${{ env.DYNAMODB_TABLE }}",
            "EMBEDDING_TYPE":"local",
            "EMBEDDING_MODEL":"all-MiniLM-L6-v2"
          }' \
          --region ${{ env.AWS_REGION }} || \
        aws lambda update-function-code \
          --function-name knowledgebot-backend \
          --image-uri ${{ needs.build-final-app.outputs.final-image }} \
          --region ${{ env.AWS_REGION }}
        
        echo "‚úÖ Lambda function deployed successfully!"

    - name: Create API Gateway (if needed)
      run: |
        echo "üåê Setting up API Gateway..."
        # Add API Gateway setup here if needed
        echo "API Gateway setup completed!"
