FROM public.ecr.aws/lambda/python:3.10

# Install system dependencies for Docling
RUN yum update -y && \
    yum install -y \
    gcc \
    gcc-c++ \
    make \
    cmake \
    git \
    wget \
    curl \
    unzip \
    libffi-devel \
    openssl-devel \
    libjpeg-devel \
    libpng-devel \
    libtiff-devel \
    freetype-devel \
    lcms2-devel \
    libwebp-devel \
    tcl-devel \
    tk-devel \
    libxml2-devel \
    libxslt-devel \
    zlib-devel \
    bzip2-devel \
    readline-devel \
    sqlite-devel \
    xz-devel \
    expat-devel \
    gdbm-devel \
    ncurses-devel \
    libuuid-devel \
    libffi-devel \
    python3-devel \
    && yum clean all

# Install core Python dependencies
RUN pip install --upgrade pip==24.0 setuptools wheel

# Pre-install NumPy to prevent upgrades during ML package installation
RUN pip install --no-cache-dir numpy==1.26.4

# Basic dependencies
RUN pip install --no-cache-dir \
    requests==2.31.0 \
    python-dotenv==1.0.0 \
    typing-extensions==4.8.0 \
    pydantic==2.5.0

# Install pandas after NumPy is locked
RUN pip install --no-cache-dir pandas==2.2.2

# Install Docling and its dependencies
RUN pip install --no-cache-dir docling>=1.2.3

# Install sentencepiece as precompiled wheel first
RUN pip install --no-cache-dir sentencepiece==0.1.99

# ML dependencies for Docling â€” allow prebuilt wheels for Python 3.10
# Install GCC 10 for C++20 support (required for ml_dtypes and optree)
RUN yum update -y && \
    yum install -y \
        gcc10 \
        gcc10-c++ \
        make \
        cmake \
    && \
    yum clean all

# Set environment variables to use GCC 10
ENV CC=/usr/bin/gcc10
ENV CXX=/usr/bin/g++10

RUN pip install --no-cache-dir \
    torch==2.1.0 \
    transformers==4.36.0 \
    sentence-transformers==2.2.2 \
    tensorflow==2.20.0

# AWS and database clients
RUN pip install --no-cache-dir \
    boto3==1.34.0 \
    botocore==1.34.0 \
    pinecone-client==2.2.4 \
    neo4j==5.15.0

# Remaining dependencies
RUN pip install --no-cache-dir \
    openai==1.12.0 \
    agents==1.4.0 \
    httpx==0.25.0 \
    orjson==3.9.10 \
    structlog==23.2.0

# Pre-download and cache all Docling models including OCR
RUN python -c "\
import os; \
os.environ['TRANSFORMERS_CACHE'] = '/tmp/transformers_cache'; \
os.environ['HF_HOME'] = '/tmp/huggingface_cache'; \
os.environ['HF_DATASETS_CACHE'] = '/tmp/huggingface_datasets_cache'; \
os.environ['TORCH_HOME'] = '/tmp/torch_cache'; \
os.environ['SENTENCE_TRANSFORMERS_HOME'] = '/tmp/sentence_transformers_cache'; \
try: \
    from docling.document_converter import DocumentConverter; \
    from docling.datamodel.base_models import InputFormat; \
    from docling.datamodel.pipeline_options import PdfPipelineOptions; \
    from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend; \
    print('Initializing Docling with OCR enabled...'); \
    pdf_options = PdfPipelineOptions(); \
    pdf_options.do_ocr = True; \
    pdf_options.do_table_structure = True; \
    pdf_options.table_structure_options.do_cell_matching = True; \
    converter = DocumentConverter( \
        format_options={InputFormat.PDF: pdf_options}, \
        backends=[PyPdfiumDocumentBackend()] \
    ); \
    print('Docling converter initialized successfully'); \
    print('OCR models and all dependencies pre-downloaded and cached'); \
except Exception as e: \
    print(f'Docling model download failed: {e}'); \
    import traceback; \
    traceback.print_exc(); \
"

# Set environment variables
ENV TRANSFORMERS_CACHE=/tmp/transformers_cache
ENV HF_HOME=/tmp/huggingface_cache
ENV HF_DATASETS_CACHE=/tmp/huggingface_datasets_cache
ENV TORCH_HOME=/tmp/torch_cache
ENV SENTENCE_TRANSFORMERS_HOME=/tmp/sentence_transformers_cache
ENV DOCLING_CACHE_DIR=/tmp/docling_cache

# Create Docling cache directory
RUN mkdir -p /tmp/docling_cache

# Copy application code
COPY agent-toolkit/ ${LAMBDA_TASK_ROOT}/

# Set the CMD to your handler
CMD ["lambda_handlers.lambda_handler_knowledge_document_ingestion"]
