FROM public.ecr.aws/lambda/python:3.11

# Set cache directories to writable locations during build
ENV TRANSFORMERS_CACHE=/tmp/transformers_cache
ENV HF_HOME=/tmp/huggingface

# Copy requirements for library installations
COPY requirements-openai-library.txt ${LAMBDA_TASK_ROOT}/

# Install heavy dependencies with pre-compiled wheels
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements-openai-library.txt

# Pre-initialize OpenAI client during build time to cache any required downloads
RUN python -c "import openai; print('OpenAI library imported successfully'); print('OpenAI version:', openai.__version__)"

# Copy the library handler
COPY microservices/openai-library-handler.py ${LAMBDA_TASK_ROOT}/

# Set the CMD to your handler
CMD ["openai-library-handler.lambda_handler"]
